{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8028c-1948-4463-af34-67574d691906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Make plots look nicer\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa1c67-5f39-44da-ba12-eed52474f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Access_to_Everyday_Life_Dataset.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b3adf-06f9-4116-85ba-e012729673a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    \"geometry/coordinates/0\": \"lon\",\n",
    "    \"geometry/coordinates/1\": \"lat\",\n",
    "    \"properties/attribute_id\": \"attribute_id\",\n",
    "    \"properties/label_type\": \"label_type\",\n",
    "    \"properties/neighborhood\": \"neighborhood\",\n",
    "    \"properties/severity\": \"severity\",\n",
    "    \"properties/is_temporary\": \"is_temporary\",\n",
    "    \"geometry/type\": \"geometry_type\",\n",
    "    \"type\": \"feature_type\"\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fee000-38d6-44a2-8157-6cb134c18d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"severity\"] = pd.to_numeric(df[\"severity\"], errors=\"coerce\")\n",
    "\n",
    "# Sometimes these come as TRUE/FALSE strings\n",
    "if df[\"is_temporary\"].dtype == \"object\":\n",
    "    df[\"is_temporary\"] = df[\"is_temporary\"].astype(str).str.upper().map({\"TRUE\": True, \"FALSE\": False})\n",
    "\n",
    "df[[\"severity\", \"is_temporary\"]].dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3aa09a-d754-4f77-8b5f-7216140d3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isna().mean().sort_values(ascending=False) * 100).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800995a-039d-4dfe-ae6a-4ebf133985f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate great-circle distance between two points on Earth (meters)\n",
    "    \"\"\"\n",
    "    R = 6371000  # Earth radius in meters\n",
    "\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    dphi = np.radians(lat2 - lat1)\n",
    "    dlambda = np.radians(lon2 - lon1)\n",
    "\n",
    "    a = (\n",
    "        np.sin(dphi / 2) ** 2\n",
    "        + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda / 2) ** 2\n",
    "    )\n",
    "    return 2 * R * np.arcsin(np.sqrt(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cfea5a-78ff-46f0-b983-f98e54dd75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap, MarkerCluster, MiniMap, Fullscreen, LocateControl, MeasureControl, Draw, Geocoder\n",
    "\n",
    "center = [df[\"lat\"].mean(), df[\"lon\"].mean()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bee362-3fde-4faa-b03e-0f1326276a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_raw = pd.read_csv(\"Seattle_Emergency_Food.csv\")\n",
    "print(\"Shape:\", food_raw.shape)\n",
    "food_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453edb2-46b0-442d-b9f4-e15f5ea37719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_first_existing(cols, candidates):\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "lat_col = pick_first_existing(food_raw.columns, [\"Latitude\", \"latitude\", \"LATITUDE\", \"lat\", \"Lat\"])\n",
    "lon_col = pick_first_existing(food_raw.columns, [\"Longitude\", \"longitude\", \"LONGITUDE\", \"lon\", \"Lon\", \"lng\", \"LON\"])\n",
    "\n",
    "name_col = pick_first_existing(food_raw.columns, [\"Agency\", \"AGENCY\", \"Name\", \"name\", \"Site Name\", \"SITE_NAME\"])\n",
    "type_col = pick_first_existing(food_raw.columns, [\"Food Resource Type\", \"FOOD_RESOURCE_TYPE\", \"Type\", \"type\"])\n",
    "\n",
    "if lat_col is None or lon_col is None:\n",
    "    raise KeyError(f\"Couldn't find lat/lon columns. Columns are: {list(food_raw.columns)}\")\n",
    "\n",
    "if name_col is None:\n",
    "    name_col = \"Agency\"  # fallback guess; adjust if needed\n",
    "\n",
    "food = food_raw.rename(columns={\n",
    "    name_col: \"poi_name\",\n",
    "    lat_col: \"lat\",\n",
    "    lon_col: \"lon\"\n",
    "}).copy()\n",
    "\n",
    "food[\"poi_type\"] = \"Emergency Food\"\n",
    "food[\"source\"] = \"Seattle Open Data\"\n",
    "\n",
    "# optional: keep subtype if available\n",
    "if type_col is not None and type_col in food_raw.columns:\n",
    "    food[\"poi_subtype\"] = food_raw[type_col]\n",
    "\n",
    "food = food.dropna(subset=[\"lat\", \"lon\", \"poi_name\"])\n",
    "food[[\"poi_name\", \"poi_type\", \"lat\", \"lon\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3aebba-2004-4fcb-a40a-c2d9f40a4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min, lat_max = df[\"lat\"].min(), df[\"lat\"].max()\n",
    "lon_min, lon_max = df[\"lon\"].min(), df[\"lon\"].max()\n",
    "\n",
    "food_seattle = food[\n",
    "    (food[\"lat\"] >= lat_min) & (food[\"lat\"] <= lat_max) &\n",
    "    (food[\"lon\"] >= lon_min) & (food[\"lon\"] <= lon_max)\n",
    "].copy()\n",
    "\n",
    "print(\"Emergency food sites inside Sidewalk coverage:\", len(food_seattle))\n",
    "food_seattle[[\"poi_name\", \"lat\", \"lon\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6994e16-9272-4adb-9d91-ae9a378fde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure these exist from earlier\n",
    "# - haversine()\n",
    "# - barriers dataframe\n",
    "\n",
    "barriers = df.dropna(subset=[\"lat\", \"lon\", \"severity\", \"is_temporary\"]).copy()\n",
    "RADIUS_METERS = 200\n",
    "\n",
    "food_results = []\n",
    "\n",
    "for _, p in food_seattle.iterrows():\n",
    "    dists = barriers.apply(\n",
    "        lambda b: haversine(p[\"lat\"], p[\"lon\"], b[\"lat\"], b[\"lon\"]),\n",
    "        axis=1\n",
    "    )\n",
    "    nearby = barriers[dists <= RADIUS_METERS]\n",
    "\n",
    "    food_results.append({\n",
    "        \"poi_name\": p[\"poi_name\"],\n",
    "        \"poi_type\": \"Emergency Food\",\n",
    "        \"barrier_count\": len(nearby),\n",
    "        \"avg_severity\": nearby[\"severity\"].mean() if len(nearby) > 0 else 0,\n",
    "        \"pct_permanent\": 1 - nearby[\"is_temporary\"].mean() if len(nearby) > 0 else 0\n",
    "    })\n",
    "\n",
    "food_access = pd.DataFrame(food_results)\n",
    "food_access[\"risk_score\"] = (\n",
    "    food_access[\"barrier_count\"] *\n",
    "    food_access[\"avg_severity\"] *\n",
    "    (1 + food_access[\"pct_permanent\"])\n",
    ")\n",
    "\n",
    "food_access.sort_values(\"risk_score\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8ef2e-ce7f-40af-b176-685e8d742285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyproj import Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b8398-cc9c-434b-ad79-8422d7e7c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Helpers ----\n",
    "def pick_first_existing(cols, candidates):\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def score_seattleish(lon, lat):\n",
    "    lon = np.asarray(lon); lat = np.asarray(lat)\n",
    "    ok = (lon > -123.5) & (lon < -121.5) & (lat > 47.0) & (lat < 48.2)\n",
    "    return ok.sum()\n",
    "\n",
    "def try_convert_xy_to_lonlat(df_in, xcol, ycol):\n",
    "    \"\"\"Try common EPSGs and return best lon/lat arrays + chosen epsg.\"\"\"\n",
    "    x = df_in[xcol].astype(float).values\n",
    "    y = df_in[ycol].astype(float).values\n",
    "\n",
    "    candidates = [3857, 2285]  # Web Mercator, WA StatePlane North (ftUS) - common for Seattle\n",
    "    best = None\n",
    "\n",
    "    for epsg in candidates:\n",
    "        transformer = Transformer.from_crs(f\"EPSG:{epsg}\", \"EPSG:4326\", always_xy=True)\n",
    "        lon, lat = transformer.transform(x, y)\n",
    "        s = score_seattleish(lon, lat)\n",
    "        if best is None or s > best[\"score\"]:\n",
    "            best = {\"epsg\": epsg, \"lon\": lon, \"lat\": lat, \"score\": s}\n",
    "\n",
    "    return best[\"lon\"], best[\"lat\"], best[\"epsg\"], best[\"score\"]\n",
    "\n",
    "def standardize_poi(df_raw, poi_type, name_candidates=None, lat_candidates=None, lon_candidates=None):\n",
    "    \"\"\"\n",
    "    Returns standardized POI dataframe with columns:\n",
    "    poi_name, poi_type, lat, lon\n",
    "    Handles either lat/lon columns OR x/y projected coordinates.\n",
    "    \"\"\"\n",
    "    name_candidates = name_candidates or [\"FACILITY\", \"Agency\", \"Name\", \"SITE_NAME\", \"Site Name\", \"SCHOOL_NM\", \"Common Name\", \"COMMON_NAME\"]\n",
    "    lat_candidates  = lat_candidates  or [\"lat\", \"Lat\", \"LAT\", \"Latitude\", \"LATITUDE\", \"Y\", \"y\"]\n",
    "    lon_candidates  = lon_candidates  or [\"lon\", \"Lon\", \"LON\", \"Longitude\", \"LONGITUDE\", \"X\", \"x\"]\n",
    "\n",
    "    cols = df_raw.columns\n",
    "\n",
    "    name_col = pick_first_existing(cols, name_candidates)\n",
    "\n",
    "    # First try direct lat/lon\n",
    "    lat_col = pick_first_existing(cols, [\"lat\",\"Lat\",\"LAT\",\"Latitude\",\"LATITUDE\"])\n",
    "    lon_col = pick_first_existing(cols, [\"lon\",\"Lon\",\"LON\",\"Longitude\",\"LONGITUDE\",\"lng\",\"LNG\"])\n",
    "\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    if lat_col and lon_col:\n",
    "        df = df.rename(columns={name_col: \"poi_name\", lat_col: \"lat\", lon_col: \"lon\"})\n",
    "        df[\"lat\"] = pd.to_numeric(df[\"lat\"], errors=\"coerce\")\n",
    "        df[\"lon\"] = pd.to_numeric(df[\"lon\"], errors=\"coerce\")\n",
    "        df[\"poi_type\"] = poi_type\n",
    "        return df[[\"poi_name\",\"poi_type\",\"lat\",\"lon\"]].dropna()\n",
    "\n",
    "    # Else try x/y\n",
    "    xcol = pick_first_existing(cols, [\"x\",\"X\",\"POINT_X\",\"EASTING\"])\n",
    "    ycol = pick_first_existing(cols, [\"y\",\"Y\",\"POINT_Y\",\"NORTHING\"])\n",
    "\n",
    "    if xcol and ycol:\n",
    "        # If x/y already look like lon/lat degrees, keep as-is\n",
    "        x = pd.to_numeric(df[xcol], errors=\"coerce\")\n",
    "        y = pd.to_numeric(df[ycol], errors=\"coerce\")\n",
    "        if x.between(-130, -100).mean() > 0.8 and y.between(40, 60).mean() > 0.8:\n",
    "            df = df.rename(columns={name_col:\"poi_name\", xcol:\"lon\", ycol:\"lat\"})\n",
    "            df[\"lat\"] = pd.to_numeric(df[\"lat\"], errors=\"coerce\")\n",
    "            df[\"lon\"] = pd.to_numeric(df[\"lon\"], errors=\"coerce\")\n",
    "            df[\"poi_type\"] = poi_type\n",
    "            return df[[\"poi_name\",\"poi_type\",\"lat\",\"lon\"]].dropna()\n",
    "\n",
    "        # Otherwise convert projected x/y into WGS84 lon/lat\n",
    "        lon, lat, epsg, score = try_convert_xy_to_lonlat(df, xcol, ycol)\n",
    "        df[\"lon\"] = lon\n",
    "        df[\"lat\"] = lat\n",
    "        df = df.rename(columns={name_col:\"poi_name\"})\n",
    "        df[\"poi_type\"] = poi_type\n",
    "        print(f\"[{poi_type}] Converted {xcol}/{ycol} using EPSG:{epsg} (Seattle-ish points: {score}/{len(df)})\")\n",
    "        return df[[\"poi_name\",\"poi_type\",\"lat\",\"lon\"]].dropna()\n",
    "\n",
    "    raise KeyError(f\"Could not find usable lat/lon or x/y columns for POI type '{poi_type}'. Columns: {list(cols)}\")\n",
    "\n",
    "def filter_to_sidewalk_coverage(pois, barriers_df):\n",
    "    lat_min, lat_max = barriers_df[\"lat\"].min(), barriers_df[\"lat\"].max()\n",
    "    lon_min, lon_max = barriers_df[\"lon\"].min(), barriers_df[\"lon\"].max()\n",
    "    return pois[\n",
    "        (pois[\"lat\"].between(lat_min, lat_max)) &\n",
    "        (pois[\"lon\"].between(lon_min, lon_max))\n",
    "    ].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850d24e-c627-4580-aa26-c242cdc3ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_raw = pd.read_csv(\"Seattle_Transit_System.csv\")\n",
    "transit_raw.head(2)\n",
    "transit_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad2684-65c3-40f0-9959-d2f9aa4176a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --------------------\n",
    "# 1) Load raw datasets\n",
    "# --------------------\n",
    "hosp_raw  = pd.read_csv(\"Seattle_Hospitals.csv\")\n",
    "food_raw  = pd.read_csv(\"Seattle_Emergency_Food.csv\")\n",
    "libs_raw  = pd.read_csv(\"Seattle_Libraries.csv\")\n",
    "parks_raw = pd.read_csv(\"Seattle_Parks_and_Rec.csv\")\n",
    "rail_raw  = pd.read_csv(\"Seattle_Light_Rails.csv\")\n",
    "pubs_raw  = pd.read_csv(\"Seattle_Public_Schools.csv\")\n",
    "pris_raw  = pd.read_csv(\"Seattle_Private_Schools.csv\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Dataset-specific FIXES FIRST\n",
    "# -------------------------------\n",
    "\n",
    "# Parks: X Coord / Y Coord -> x/y (so standardize_poi detects them)\n",
    "parks_raw = parks_raw.rename(columns={\"X Coord\": \"x\", \"Y Coord\": \"y\"})\n",
    "\n",
    "# Public schools: force a usable name column -> \"Name\"\n",
    "pub_name_col = None\n",
    "for c in [\"school_name\", \"SCHOOL_NAME\", \"SCHOOL_NM\", \"NAME\", \"Name\"]:\n",
    "    if c in pubs_raw.columns:\n",
    "        pub_name_col = c\n",
    "        break\n",
    "if pub_name_col is None:\n",
    "    # heuristic: first column containing 'name'\n",
    "    candidates = [c for c in pubs_raw.columns if \"name\" in c.lower()]\n",
    "    pub_name_col = candidates[0] if candidates else None\n",
    "\n",
    "print(\"Public school name column:\", pub_name_col)\n",
    "pubs_raw_fixed = pubs_raw.rename(columns={pub_name_col: \"Name\"}) if pub_name_col else pubs_raw\n",
    "\n",
    "# Private schools: force a usable name column -> \"Name\"\n",
    "pri_name_col = None\n",
    "for c in [\"school_name\", \"SCHOOL_NAME\", \"SCHOOL_NM\", \"NAME\", \"Name\"]:\n",
    "    if c in pris_raw.columns:\n",
    "        pri_name_col = c\n",
    "        break\n",
    "if pri_name_col is None:\n",
    "    candidates = [c for c in pris_raw.columns if \"name\" in c.lower()]\n",
    "    pri_name_col = candidates[0] if candidates else None\n",
    "\n",
    "print(\"Private school name column:\", pri_name_col)\n",
    "pris_raw_fixed = pris_raw.rename(columns={pri_name_col: \"Name\"}) if pri_name_col else pris_raw\n",
    "\n",
    "# --------------------\n",
    "# 3) Standardize ONCE\n",
    "# --------------------\n",
    "hosp  = standardize_poi(hosp_raw,  \"Hospital\",       name_candidates=[\"FACILITY\",\"Facility\",\"NAME\",\"Name\"])\n",
    "food  = standardize_poi(food_raw,  \"Emergency Food\", name_candidates=[\"Agency\",\"AGENCY\",\"Name\",\"SITE_NAME\",\"Site Name\"])\n",
    "libs  = standardize_poi(libs_raw,  \"Library\",        name_candidates=[\"Name\",\"NAME\",\"LIBRARY\",\"Library\",\"Common Name\",\"COMMON_NAME\"])\n",
    "parks = standardize_poi(parks_raw, \"Parks & Rec\",    name_candidates=[\"Name\",\"NAME\",\"PARK_NAME\",\"Park Name\",\"COMMON_NAME\",\"Common Name\"])\n",
    "rail  = standardize_poi(rail_raw,  \"Light Rail\",     name_candidates=[\"Name\",\"NAME\",\"STATION\",\"Station\",\"STOP_NAME\",\"stop_name\"])\n",
    "\n",
    "# IMPORTANT: use the FIXED dataframes here (not pubs_raw / pris_raw)\n",
    "pubs  = standardize_poi(pubs_raw_fixed, \"Public School\",  name_candidates=[\"Name\",\"NAME\",\"SCHOOL_NM\",\"SCHOOL_NAME\",\"School Name\"])\n",
    "pris  = standardize_poi(pris_raw_fixed, \"Private School\", name_candidates=[\"Name\",\"NAME\",\"SCHOOL_NM\",\"SCHOOL_NAME\",\"School Name\"])\n",
    "\n",
    "# --------------------\n",
    "# 4) Combine\n",
    "# --------------------\n",
    "pois_all = pd.concat([hosp, food, libs, parks, rail, pubs, pris], ignore_index=True).dropna()\n",
    "\n",
    "print(\"Total POIs (all types):\", len(pois_all))\n",
    "display(pois_all[\"poi_type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812cc54-14e7-4a94-83aa-77cd6fef2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Model for predicting POI Risk\n",
    "from sklearn.neighbors import BallTree\n",
    "import numpy as np\n",
    "\n",
    "def compute_poi_risk(pois, barriers, radius_m=200):\n",
    "\n",
    "    # Convert to radians for BallTree (haversine)\n",
    "    pois_rad = np.deg2rad(pois[[\"lat\",\"lon\"]].values)\n",
    "    bars_rad = np.deg2rad(barriers[[\"lat\",\"lon\"]].values)\n",
    "\n",
    "    tree = BallTree(bars_rad, metric=\"haversine\")\n",
    "    radius = radius_m / 6371000  # meters → radians\n",
    "\n",
    "    results = []\n",
    "    for i, idxs in enumerate(tree.query_radius(pois_rad, r=radius)):\n",
    "        nearby = barriers.iloc[idxs]\n",
    "        results.append({\n",
    "            \"barrier_count\": len(nearby),\n",
    "            \"avg_severity\": nearby[\"severity\"].mean() if len(nearby) else 0,\n",
    "            \"pct_permanent\": (\n",
    "                (~nearby[\"is_temporary\"]).mean() if len(nearby) else 0\n",
    "            )\n",
    "        })\n",
    "\n",
    "    risk = pd.DataFrame(results)\n",
    "    out = pd.concat([pois.reset_index(drop=True), risk], axis=1)\n",
    "\n",
    "    # Simple composite risk score (interpretable!)\n",
    "    out[\"risk_score\"] = (\n",
    "        out[\"barrier_count\"]\n",
    "        * out[\"avg_severity\"]\n",
    "        * (1 + out[\"pct_permanent\"])\n",
    "    )\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6191c1f-3490-4211-84f3-a8b0579c6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_risk = compute_poi_risk(pois_all, df)\n",
    "pois_risk.sort_values(\"risk_score\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61822488-0325-4439-9c2f-a1eee0fc3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "\n",
    "from folium.plugins import (\n",
    "    HeatMap, MarkerCluster, MiniMap, Fullscreen, LocateControl,\n",
    "    MeasureControl, Draw, Geocoder\n",
    ")\n",
    "from folium import IFrame\n",
    "\n",
    "# -------------------------\n",
    "# 0) Setup + safety cleaning\n",
    "# -------------------------\n",
    "needed = [\"lat\", \"lon\", \"severity\", \"label_type\", \"neighborhood\", \"is_temporary\"]\n",
    "for c in needed:\n",
    "    if c not in df.columns:\n",
    "        raise KeyError(f\"Missing column '{c}'. Current columns: {list(df.columns)}\")\n",
    "\n",
    "df_clean = df.copy()\n",
    "df_clean[\"severity\"] = pd.to_numeric(df_clean[\"severity\"], errors=\"coerce\")\n",
    "if df_clean[\"is_temporary\"].dtype == \"object\":\n",
    "    df_clean[\"is_temporary\"] = df_clean[\"is_temporary\"].astype(str).str.upper().map({\"TRUE\": True, \"FALSE\": False})\n",
    "\n",
    "center = [df_clean[\"lat\"].mean(), df_clean[\"lon\"].mean()]\n",
    "\n",
    "# -------------------------\n",
    "# 1) Base map (RENAMED)\n",
    "# -------------------------\n",
    "m_super = folium.Map(location=center, zoom_start=12, tiles=\"CartoDB positron\")\n",
    "\n",
    "# Global tools\n",
    "MiniMap(toggle_display=True).add_to(m_super)\n",
    "Fullscreen(position=\"topright\").add_to(m_super)\n",
    "LocateControl(auto_start=False).add_to(m_super)\n",
    "MeasureControl(position=\"topleft\").add_to(m_super)\n",
    "\n",
    "Geocoder(collapsed=True, add_marker=True).add_to(m_super)\n",
    "\n",
    "Draw(\n",
    "    export=True,\n",
    "    filename=\"selected_area.geojson\",\n",
    "    position=\"topleft\",\n",
    "    draw_options={\"polyline\": False, \"circle\": False, \"circlemarker\": False}\n",
    ").add_to(m_super)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2) View A: Interactive Heatmap (severity-weighted)\n",
    "# ---------------------------------------------------\n",
    "heat_fg = folium.FeatureGroup(name=\"VIEW: Heatmap (weighted by severity)\", show=False)\n",
    "heat_data = df_clean[[\"lat\", \"lon\", \"severity\"]].dropna().values.tolist()\n",
    "HeatMap(heat_data, radius=10, blur=15, max_zoom=13).add_to(heat_fg)\n",
    "heat_fg.add_to(m_super)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 3) View B: Clustered Markers (basic)\n",
    "# ----------------------------------------------------------------\n",
    "cluster_fg = folium.FeatureGroup(name=\"VIEW: Clustered Markers (basic)\", show=False)\n",
    "cluster = MarkerCluster().add_to(cluster_fg)\n",
    "\n",
    "sample_basic = df_clean.dropna(subset=[\"lat\",\"lon\"]).sample(min(3000, len(df_clean)), random_state=7)\n",
    "for _, r in sample_basic.iterrows():\n",
    "    popup = (f\"Type: {r['label_type']}<br>\"\n",
    "             f\"Neighborhood: {r['neighborhood']}<br>\"\n",
    "             f\"Severity: {r['severity']}<br>\"\n",
    "             f\"Temporary: {r['is_temporary']}\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r[\"lat\"], r[\"lon\"]],\n",
    "        radius=3,\n",
    "        popup=popup,\n",
    "        fill=True\n",
    "    ).add_to(cluster)\n",
    "\n",
    "cluster_fg.add_to(m_super)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) View C: Clustered Markers (rich HTML popup w/ severity badge)\n",
    "# ---------------------------------------------------------------------\n",
    "badge_fg = folium.FeatureGroup(name=\"VIEW: Clustered Markers (rich popups)\", show=False)\n",
    "badge_cluster = MarkerCluster().add_to(badge_fg)\n",
    "\n",
    "sample_badge = df_clean.dropna(subset=[\"lat\",\"lon\",\"severity\"]).sample(min(2000, len(df_clean)), random_state=7)\n",
    "for _, r in sample_badge.iterrows():\n",
    "    sev = int(r[\"severity\"]) if pd.notna(r[\"severity\"]) else \"NA\"\n",
    "    temp = r[\"is_temporary\"]\n",
    "\n",
    "    html = f\"\"\"\n",
    "    <div style=\"font-family: Arial; font-size: 14px;\">\n",
    "      <div style=\"font-size:16px; font-weight:700;\">{r['label_type']}</div>\n",
    "      <div><b>Neighborhood:</b> {r['neighborhood']}</div>\n",
    "      <div><b>Severity:</b>\n",
    "        <span style=\"padding:2px 6px; border-radius:8px; border:1px solid #999;\">\n",
    "          {sev}\n",
    "        </span>\n",
    "      </div>\n",
    "      <div><b>Temporary:</b> {temp}</div>\n",
    "      <div style=\"margin-top:6px; color:#666;\">\n",
    "        ({r['lat']:.5f}, {r['lon']:.5f})\n",
    "      </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    iframe = IFrame(html=html, width=270, height=150)\n",
    "    folium.Marker([r[\"lat\"], r[\"lon\"]], popup=folium.Popup(iframe)).add_to(badge_cluster)\n",
    "\n",
    "badge_fg.add_to(m_super)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5) View D: Toggles (perm/temp/severe)\n",
    "# -------------------------------------------------------------\n",
    "toggle_group = folium.FeatureGroup(name=\"VIEW: Toggle layers (perm/temp/severe)\", show=False)\n",
    "\n",
    "fg_perm = folium.FeatureGroup(name=\"Permanent (not temporary)\")\n",
    "fg_temp = folium.FeatureGroup(name=\"Temporary\")\n",
    "fg_severe = folium.FeatureGroup(name=\"Severe (severity ≥ 4)\")\n",
    "\n",
    "clean = df_clean.dropna(subset=[\"lat\",\"lon\",\"severity\",\"is_temporary\"]).sample(min(5000, len(df_clean)), random_state=7)\n",
    "\n",
    "for _, r in clean.iterrows():\n",
    "    popup = (f\"Type: {r['label_type']}<br>\"\n",
    "             f\"Neighborhood: {r['neighborhood']}<br>\"\n",
    "             f\"Severity: {r['severity']}<br>\"\n",
    "             f\"Temporary: {r['is_temporary']}\")\n",
    "\n",
    "    marker = folium.CircleMarker(\n",
    "        location=[r[\"lat\"], r[\"lon\"]],\n",
    "        radius=3,\n",
    "        popup=popup,\n",
    "        fill=True\n",
    "    )\n",
    "\n",
    "    if r[\"is_temporary\"] == True:\n",
    "        marker.add_to(fg_temp)\n",
    "    else:\n",
    "        marker.add_to(fg_perm)\n",
    "\n",
    "    if r[\"severity\"] >= 4:\n",
    "        folium.CircleMarker(\n",
    "            location=[r[\"lat\"], r[\"lon\"]],\n",
    "            radius=4,\n",
    "            popup=popup,\n",
    "            fill=True\n",
    "        ).add_to(fg_severe)\n",
    "\n",
    "fg_perm.add_to(toggle_group)\n",
    "fg_temp.add_to(toggle_group)\n",
    "fg_severe.add_to(toggle_group)\n",
    "\n",
    "toggle_group.add_to(m_super)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6) View E: Severity grid overlay\n",
    "# -------------------------------------------------------------\n",
    "def make_grid(df_in, cell_size=0.003):\n",
    "    d = df_in.dropna(subset=[\"lat\",\"lon\",\"severity\"]).copy()\n",
    "    d[\"gx\"] = (d[\"lon\"] / cell_size).astype(int)\n",
    "    d[\"gy\"] = (d[\"lat\"] / cell_size).astype(int)\n",
    "\n",
    "    agg = d.groupby([\"gx\",\"gy\"]).agg(n=(\"severity\",\"size\"), avg_sev=(\"severity\",\"mean\")).reset_index()\n",
    "    agg[\"lon_min\"] = agg[\"gx\"] * cell_size\n",
    "    agg[\"lon_max\"] = (agg[\"gx\"] + 1) * cell_size\n",
    "    agg[\"lat_min\"] = agg[\"gy\"] * cell_size\n",
    "    agg[\"lat_max\"] = (agg[\"gy\"] + 1) * cell_size\n",
    "    return agg\n",
    "\n",
    "grid_fg = folium.FeatureGroup(name=\"VIEW: Severity grid overlay\", show=False)\n",
    "grid = make_grid(df_clean, cell_size=0.003)\n",
    "\n",
    "for _, r in grid.iterrows():\n",
    "    if r[\"n\"] < 5:\n",
    "        continue\n",
    "    opacity = min(0.85, max(0.1, (r[\"avg_sev\"] - 1) / 4))\n",
    "    folium.Rectangle(\n",
    "        bounds=[[r[\"lat_min\"], r[\"lon_min\"]], [r[\"lat_max\"], r[\"lon_max\"]]],\n",
    "        fill=True, fill_opacity=opacity, weight=0,\n",
    "        popup=f\"Count: {int(r['n'])}<br>Avg severity: {r['avg_sev']:.2f}\"\n",
    "    ).add_to(grid_fg)\n",
    "\n",
    "grid_fg.add_to(m_super)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7) View F: Top barrier types\n",
    "# -------------------------------------------------------------\n",
    "types_view = folium.FeatureGroup(name=\"VIEW: Barrier types (top 6 toggles)\", show=False)\n",
    "\n",
    "clean2 = df_clean.dropna(subset=[\"lat\",\"lon\",\"label_type\",\"severity\"])\n",
    "top_types = clean2[\"label_type\"].value_counts().head(6).index\n",
    "type_layers = {t: folium.FeatureGroup(name=f\"Type: {t}\") for t in top_types}\n",
    "\n",
    "sample_types = clean2[clean2[\"label_type\"].isin(top_types)].sample(min(6000, len(clean2)), random_state=7)\n",
    "for _, r in sample_types.iterrows():\n",
    "    popup = (f\"Type: {r['label_type']}<br>\"\n",
    "             f\"Neighborhood: {r['neighborhood']}<br>\"\n",
    "             f\"Severity: {r['severity']}\")\n",
    "    folium.CircleMarker(\n",
    "        location=[r[\"lat\"], r[\"lon\"]],\n",
    "        radius=3,\n",
    "        popup=popup,\n",
    "        fill=True\n",
    "    ).add_to(type_layers[r[\"label_type\"]])\n",
    "\n",
    "for _, fg in type_layers.items():\n",
    "    fg.add_to(types_view)\n",
    "\n",
    "types_view.add_to(m_super)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7.5) POIs: All essential services (ONE toggle)\n",
    "# -------------------------------------------------------------\n",
    "# Requires: pois_risk dataframe exists\n",
    "required_poi_cols = [\"lat\", \"lon\", \"poi_name\", \"poi_type\", \"risk_score\", \"barrier_count\", \"avg_severity\"]\n",
    "for c in required_poi_cols:\n",
    "    if c not in pois_risk.columns:\n",
    "        raise KeyError(f\"pois_risk missing '{c}'. Columns: {list(pois_risk.columns)}\")\n",
    "\n",
    "pois_plot = pois_risk.dropna(subset=[\"lat\",\"lon\"]).copy()\n",
    "pois_plot[\"lat\"] = pd.to_numeric(pois_plot[\"lat\"], errors=\"coerce\")\n",
    "pois_plot[\"lon\"] = pd.to_numeric(pois_plot[\"lon\"], errors=\"coerce\")\n",
    "pois_plot = pois_plot.dropna(subset=[\"lat\",\"lon\"])\n",
    "\n",
    "poi_fg = folium.FeatureGroup(name=\"POIs: Essential Services (risk-weighted)\", show=False)\n",
    "\n",
    "color_map = {\n",
    "    \"Hospital\": \"red\",\n",
    "    \"Emergency Food\": \"darkred\",\n",
    "    \"Library\": \"blue\",\n",
    "    \"Public School\": \"green\",\n",
    "    \"Private School\": \"lightgreen\",\n",
    "    \"Parks & Rec\": \"darkgreen\",\n",
    "    \"Light Rail\": \"purple\"\n",
    "}\n",
    "\n",
    "# Optional: limit for performance\n",
    "top_n = 800\n",
    "pois_plot = pois_plot.sort_values(\"risk_score\", ascending=False).head(top_n)\n",
    "\n",
    "for _, r in pois_plot.iterrows():\n",
    "    popup = f\"\"\"\n",
    "    <b>{r['poi_name']}</b><br>\n",
    "    Type: {r['poi_type']}<br>\n",
    "    Risk score: {r['risk_score']:.2f}<br>\n",
    "    Barriers (200m): {int(r['barrier_count'])}<br>\n",
    "    Avg severity: {r['avg_severity']:.2f}\n",
    "    \"\"\"\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[float(r[\"lat\"]), float(r[\"lon\"])],\n",
    "        radius=4 + min(float(r[\"risk_score\"]) / 10, 6),\n",
    "        color=color_map.get(r[\"poi_type\"], \"gray\"),\n",
    "        fill=True,\n",
    "        fill_opacity=0.75,\n",
    "        popup=popup\n",
    "    ).add_to(poi_fg)\n",
    "\n",
    "poi_fg.add_to(m_super)\n",
    "\n",
    "# -------------------------\n",
    "# 8) Layer control + save\n",
    "# -------------------------\n",
    "folium.LayerControl(collapsed=False).add_to(m_super)\n",
    "\n",
    "m_super.save(\"all_views_accessibility_map_with_pois.html\")\n",
    "m_super\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
